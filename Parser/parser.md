# Python3 Parser

## The tokenizer and parser module
In pgen we explored how to create the grammar file graminit.h, gramminit.c, this chapter will explore how the tokenizer and parser work together to create the AST. Let's start from the function PyParser_ParseFileObject (in Parser/parsetok.c)

```c++ parsetok.c
164 node *
165 PyParser_ParseFileObject(FILE *fp, PyObject *filename,
166                          const char *enc, grammar *g, int start,
167                          const char *ps1, const char *ps2,
168                          perrdetail *err_ret, int *flags)
169 {
170     struct tok_state *tok;
171 
172     if (initerr(err_ret, filename) < 0)
173         return NULL;
174 
175     if (PySys_Audit("compile", "OO", Py_None, err_ret->filename) < 0) {
176         return NULL;
177     }
178 
179     if ((tok = PyTokenizer_FromFile(fp, enc, ps1, ps2)) == NULL) {
180         err_ret->error = E_NOMEM;
181         return NULL;
182     }
183     if (*flags & PyPARSE_TYPE_COMMENTS) {
184         tok->type_comments = 1;
185     }
186     Py_INCREF(err_ret->filename);
187     tok->filename = err_ret->filename;
188     return parsetok(tok, g, start, err_ret, flags);
189 }

```
The grammar *g is the grammar struct generated by pgen, PyParser_ParseFileObject first creates a tokenizer PyTokenizer_FromFile, and passes it with g to the function parsetok.

```c++
212 /* Parse input coming from the given tokenizer structure.
213    Return error code. */
214 
215 static node *
216 parsetok(struct tok_state *tok, grammar *g, int start, perrdetail *err_ret,
217          int *flags)
```

parsetok creates a parser, using the grammar g
```c++ 
232     /* create a parser and install the accelerator, 
233      * accelerator can index the next state much faster. */
234     if ((ps = PyParser_New(g, start)) == NULL) {
235         err_ret->error = E_NOMEM;
236         growable_comment_array_deallocate(&type_ignores);
237         PyTokenizer_Free(tok);
238         return NULL;
239     }
```

parsetok then get the token by calling PyTokenizer_Get
```c++
247     for (;;) {
248         const char *a, *b;
249         int type;
250         size_t len;
251         char *str;
252         col_offset = -1;
253         int lineno;
254         const char *line_start;
255 
256         type = PyTokenizer_Get(tok, &a, &b);
257 
258         len = (a != NULL && b != NULL) ? b - a : 0;
259         str = (char *) PyObject_MALLOC(len + 1);
260         if (str == NULL) {
261             err_ret->error = E_NOMEM;
262             break;
263         }
264         if (len > 0)
265             strncpy(str, a, len);
266         str[len] = '\0';
```

if the token is valid, then PyParser_AddToken will add the token into the parser
for constructing the AST
```c++
337         if ((err_ret->error =
338              PyParser_AddToken(ps, (int)type, str,
339                                lineno, col_offset, tok->lineno, end_col_offset,
340                                &(err_ret->expected))) != E_OK) {
341             if (tok->done == E_EOF && !ISWHITESPACE(type)) {
342                 tok->done = E_SYNTAX;
343             }
344             if (err_ret->error != E_DONE) {
345                 PyObject_FREE(str);
346                 err_ret->token = type;
347             }
348             break;
349         }
350     }
```

returns the AST if the AST has been construct correctly.
```c++
459 done:
460     PyTokenizer_Free(tok);
461 
462     if (n != NULL) {
463         _PyNode_FinalizeEndPos(n);
464     }
465     return n;
```
The parsing process can be viewed in this image. 

![](images/Parser-Tokenizer.png)


## How does accelerator work?
The function PyParser_AddToken handles the state transition when parsing the different tokens. When the parser is created, it installs a accelerator module (accel.c)

before installing the accelerator, parser has to check the list of the arc structure to decide where the next state to go, it would waste a lot of time. Because now python has already got the DFA, every single token will **only** lead to a new state, it would be much faster if it can use a indexing strategy, something like ```next_state = current_state.accel[label index]```.

``` c++
typedef struct {
    short       a_lbl;          /* Label of this arc */
    short       a_arrow;        /* State where this arc goes to */
} arc;
```

This is what accel.c does, some details are omitted.
```c++
static void fixstate(grammar *g, state *s)
{
    const arc *a;
    int k;
    int *accel;
    int nl = g->g_ll.ll_nlabels;
    s->s_accept = 0;

    /* 1. create an accel array for the acceleration */
    accel = (int *) PyObject_MALLOC(nl * sizeof(int));

    /* 2. default case: there are no acceleration */
    for (k = 0; k < nl; k++)
        accel[k] = -1;

    /* 3. for each arc, get the label and the next state. */
    a = s->s_arc; /* a point to the arcs array[0] */
    for (k = s->s_narcs; --k >= 0; a++) {
        int lbl = a->a_lbl; /* label index */
        const label *l = &g->g_ll.ll_label[lbl];
        int type = l->lb_type; /* Non-terminal symbol or token num */
        if (a->a_arrow >= (1 << 7)) { /* more than 127 states(in the dfa that 
                                      having s as its state), could this happen? */
            printf("XXX too many states!\n");
            continue;
        }
        if (ISNONTERMINAL(type)) {
            const dfa *d1 = PyGrammar_FindDFA(g, type); /* g_dfa[type - NT_OFFSET];*/
            int ibit;
            if (type - NT_OFFSET >= (1 << 7)) {
                printf("XXX too high nonterminal number!\n");
                continue;
            }
            for (ibit = 0; ibit < g->g_ll.ll_nlabels; ibit++) {
                if (testbit(d1->d_first, ibit)) {
                    if (accel[ibit] != -1)
                        printf("XXX ambiguity!\n");

                    /* 4. if the label is a Non-terminal symbol, using its first set to
                     * get the next state. */
                    accel[ibit] = a->a_arrow | (1 << 7) |
                        ((type - NT_OFFSET) << 8);  /* next_state | (1<<7) |  Non-terminal */
                }
            }
        }
        else if (lbl == EMPTY)
            s->s_accept = 1;
        /* 5: if the label is a token. set the next state by the the label index directly. */
        else if (lbl >= 0 && lbl < nl)
            accel[lbl] = a->a_arrow;
    }

    // ...
}
```



